{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24919ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9542d5",
   "metadata": {},
   "source": [
    "## Load data and train a feedforward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9371ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlggm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatamodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ApneaDataModule\n",
      "File \u001b[0;32m/tungstenfs/scratch/gzenke/agarmanv/cnn_graph/lib/mlggm/datamodules.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random_split\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlggm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Apnea\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from lib.mlggm.datamodules import ApneaDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0540c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:  15309\n",
      "Size of validation set:  1701\n"
     ]
    }
   ],
   "source": [
    "dm = ApneaDataModule(\n",
    "    batch_size=1024, num_workers=4, shuffle=False, path=\"./data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c3b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.mlggm.ff_model import FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34c05d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8148796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c938123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.mlggm.callback import MetricTracker\n",
    "cb = MetricTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "928e1bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agarmanv/Documents/cnn_graph/cnn_venv/lib/python3.8/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=10, check_val_every_n_epoch=2, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea5aea0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | loss_fn       | BCEWithLogitsLoss | 0     \n",
      "1 | hidden_layer  | Linear            | 6.1 M \n",
      "2 | nonlin        | Sigmoid           | 0     \n",
      "3 | readout_layer | Linear            | 1.0 K \n",
      "----------------------------------------------------\n",
      "6.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.584    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agarmanv/Documents/cnn_graph/cnn_venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1933: PossibleUserWarning: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bddcb911de7240c7843e5523898dad48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d08d7ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'test/loss_step': tensor(0.8174),\n",
       "  'test/acc_step': tensor(0.3456),\n",
       "  'test/loss_epoch': tensor(0.8036),\n",
       "  'test/acc_epoch': tensor(0.3704)},\n",
       " {'train/loss_step': tensor(0.6746),\n",
       "  'train/loss_epoch': tensor(0.6753),\n",
       "  'test/loss_step': tensor(0.6487),\n",
       "  'test/acc_step': tensor(0.6544),\n",
       "  'test/loss_epoch': tensor(0.6691),\n",
       "  'test/acc_epoch': tensor(0.6296)},\n",
       " {'train/loss_step': tensor(0.6746),\n",
       "  'train/loss_epoch': tensor(0.6753),\n",
       "  'test/loss_step': tensor(0.6487),\n",
       "  'test/acc_step': tensor(0.6544),\n",
       "  'test/loss_epoch': tensor(0.6691),\n",
       "  'test/acc_epoch': tensor(0.6296)},\n",
       " {'train/loss_step': tensor(0.6746),\n",
       "  'train/loss_epoch': tensor(0.6753),\n",
       "  'test/loss_step': tensor(0.6487),\n",
       "  'test/acc_step': tensor(0.6544),\n",
       "  'test/loss_epoch': tensor(0.6691),\n",
       "  'test/acc_epoch': tensor(0.6296)},\n",
       " {'train/loss_step': tensor(0.6746),\n",
       "  'train/loss_epoch': tensor(0.6753),\n",
       "  'test/loss_step': tensor(0.6487),\n",
       "  'test/acc_step': tensor(0.6544),\n",
       "  'test/loss_epoch': tensor(0.6691),\n",
       "  'test/acc_epoch': tensor(0.6296)},\n",
       " {'train/loss_step': tensor(0.6746),\n",
       "  'train/loss_epoch': tensor(0.6753),\n",
       "  'test/loss_step': tensor(0.6487),\n",
       "  'test/acc_step': tensor(0.6544),\n",
       "  'test/loss_epoch': tensor(0.6691),\n",
       "  'test/acc_epoch': tensor(0.6296)}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb.elogs_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08236f6e",
   "metadata": {},
   "source": [
    "To see results below with tensorboard, go to your terminal and run:\n",
    "`tensorboard --logdir=lightning_logs/`<br>\n",
    "Then run the cell below to see training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "556d32f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 149707), started 0:01:51 ago. (Use '!kill 149707' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d2a55cc1b7b0e5fe\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d2a55cc1b7b0e5fe\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f3e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
